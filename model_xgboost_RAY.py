import pandas as pd
import numpy as np
from sklearn.metrics import f1_score, recall_score, roc_auc_score
import xgboost as xgb
import time
from datetime import datetime
import mlflow
import joblib
import os
import json

import ray
from ray import tune
from ray.tune import CheckpointConfig
from ray.tune.search import BasicVariantGenerator
from ray.util.metrics import Counter, Histogram, Gauge
from ray.air.integrations.mlflow import MLflowLoggerCallback
from ray.air import session

# Import preprocessing functions from your preprocess file
from preprocess import prepare_xgboost_data, preprocess_leads

# SETUP ============================================================
print("=" * 50)
print("SETUP")
print("=" * 50)

# Get raw data
df_leads_raw = pd.read_csv("data/leads_raw.csv")
print(f"‚úÖ Loaded raw data with {df_leads_raw.shape[0]} records and {df_leads_raw.shape[1]} features.")

# MLflow setup
mlflow.set_tracking_uri("file:./mlruns")
print(f"üñ•Ô∏è MLflow tracking URI: {mlflow.get_tracking_uri()}")

experiment_name = f"xgboost_ray_experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
print(f"üñ•Ô∏è Experiment name: {experiment_name}")

# Define the metric to optimize
METRIC = "roc_auc"
print(f"üñ•Ô∏è Using metric: {METRIC} for optimization")

# Initialize Ray
ray.init(
    num_cpus=6,
    object_store_memory=2_000_000_000,
    log_to_driver=False,
    include_dashboard=True,
    _metrics_export_port=8080  # Enable Prometheus metrics
)
print(f"‚úÖ Ray initialized with resources: {ray.cluster_resources()}\n\n")

# PREPROCESS ============================================================
print("=" * 50)
print("PREPROCESS")
print("=" * 50)

# Apply general preprocessing
df_leads_processed = preprocess_leads(df_leads_raw)
print(f"‚úÖ Preprocessed data with {df_leads_processed.shape[0]} records and {df_leads_processed.shape[1]} features.")
print(f"‚úÖ Preprocessing completed! Saved {df_leads_processed.shape[0]} records with {df_leads_processed.shape[1]} features.")
print("üìù Data saved to: data/leads_cleaned.csv\n")

# Use the preprocessing function from preprocess.py
X_train, X_val, X_test, y_train, y_val, y_test, label_encoders = prepare_xgboost_data(
    data_path="data/leads_cleaned.csv",
    test_size=0.2,
    val_size=0.2,
    random_state=123
)

# Save the test set to CSV files
X_test.to_csv("data/X_test.csv", index=False)
y_test.to_csv("data/y_test.csv", index=False)

print("‚úÖ Test set saved to 'data/X_test.csv' and 'data/y_test.csv'")

# Convert validation and test sets to numpy arrays
y_train = y_train.to_numpy()
y_val = y_val.to_numpy()
y_test = y_test.to_numpy()

# Store large objects in the Ray object store (for efficient distributed access)
X_train_ref = ray.put(X_train)
X_val_ref = ray.put(X_val)
X_test_ref = ray.put(X_test)
y_train_ref = ray.put(y_train)
y_val_ref = ray.put(y_val)
y_test_ref = ray.put(y_test)

print("‚úÖ Preprocessing completed using imported function!")
print(f"‚úÖ Ready for XGBoost training with {X_train.shape[0]} training samples.\n\n")

# XGBoost: Function ===================================================
print("=" * 50)
print("XGBoost: Trainable Function")
print("=" * 50)

# Custom metrics
trial_counter = Counter("xgboost_trials_total", description="Total XGBoost trials completed")
training_time_histogram = Histogram(
    "xgboost_training_duration_seconds", 
    description="XGBoost training time",
    boundaries=[0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 30.0, 60.0]  # Time buckets in seconds
)
roc_auc_gauge = Gauge("xgboost_best_roc_auc", description="Best ROC AUC achieved")

def trainable_xgboost(config):
    """Train XGBoost model with Ray Tune and Prometheus metrics"""
    start_time = time.time()
    
    # Retrieve data from Ray object store
    X_train = ray.get(X_train_ref)
    X_val = ray.get(X_val_ref)
    y_train = ray.get(y_train_ref)
    y_val = ray.get(y_val_ref)

    # Initialize XGB
    model = xgb.XGBClassifier(
        max_depth=config["max_depth"],
        learning_rate=config["learning_rate"],
        n_estimators=config["n_estimators"],
        subsample=config["subsample"],
        colsample_bytree=config["colsample_bytree"],
        tree_method="hist",
        random_state=42,
        eval_metric="logloss",
        verbosity=0,
        n_jobs=1
    )

    # Train model
    model.fit(X_train, y_train)
    
    # Predictions on validation set
    y_val_pred = model.predict(X_val)
    y_val_pred_proba = model.predict_proba(X_val)[:, 1]

    # Metrics on validation set
    f1 = f1_score(y_val, y_val_pred)
    recall = recall_score(y_val, y_val_pred)
    roc_auc = roc_auc_score(y_val, y_val_pred_proba)
    
    # Save checkpoint AFTER training and metrics calculation
    checkpoint_dir = os.path.join("checkpoints", f"trial_{time.time()}")
    os.makedirs(checkpoint_dir, exist_ok=True)
    model_path = os.path.join(checkpoint_dir, "model.pkl")
    joblib.dump(model, model_path)


    # Record Prometheus metrics
    trial_counter.inc()
    training_time_histogram.observe(time.time() - start_time)
    roc_auc_gauge.set(roc_auc)

    # Report to Ray
    tune.report({"f1": f1, "recall": recall, "roc_auc": roc_auc})

print("üî• XGBoost trainable function defined with Ray Tune and Prometheus metrics!\n\n")

# RAY: Tune ===========================================================
print("=" * 50)
print(f" RAY TUNE: {METRIC}")
print("=" * 50)

NUM_OF_TRIALS = 24
WORKERS = 6

# RAY: Search Space
search_space = {
    'max_depth': tune.randint(3, 8),
    'learning_rate': tune.uniform(0.01, 0.3),
    'n_estimators': tune.randint(50, 200),  # Smaller range for faster trials
    'subsample': tune.uniform(0.7, 1.0),
    'colsample_bytree': tune.uniform(0.7, 1.0)
}
print(f"üî• Search Space: {search_space}")

# RAY: Tune Configuration
tune_config = tune.TuneConfig(
    metric=METRIC,
    mode="max",
    num_samples=NUM_OF_TRIALS,
    max_concurrent_trials=WORKERS,
    search_alg=BasicVariantGenerator(random_state=42) 
)
print(f"üî• Tune Config: Random Search w/ {NUM_OF_TRIALS} trials, {WORKERS} workers.")

# RAY: Run Configuration
run_config=tune.RunConfig(
        name=f"RAY_xgboost_els_{METRIC}_random",
        storage_path='/Users/isiomamabatah/Desktop/Python/Projects/Email_Lead_Scoring/results',
        callbacks=[
            MLflowLoggerCallback(
                tracking_uri="file:./mlruns",
                experiment_name=experiment_name,
                save_artifact=True,
                tags={"algorithm": "random_search", "model": "xgboost"}
            )
        ],
        checkpoint_config = CheckpointConfig(
            num_to_keep=1,  # Keep only the best checkpoint
            checkpoint_score_attribute=METRIC,  # Metric to monitor
            checkpoint_score_order="max"  # Higher roc_auc is better
        )

)
print("üî• Run Config: set with MLflow logging and checkpointing.")

# Run Ray Tune: 
# - Random Search Algorithm
tuner_Random = tune.Tuner(
    trainable=trainable_xgboost,
    tune_config=tune_config,
    param_space=search_space,
    run_config=run_config
)
print("üî•üî• Ray Tuner:  Initialized! üî•üî•\n\n")
# RAY: Scheduler (Explore FUTURE)

# XGBoost: RAY FIT ===========================================================
print("=" * 50)
print(f"üëæ XGBoost: RAY Fit {METRIC} üëæ")
print("=" * 50)

results_Random = tuner_Random.fit()
print("‚úÖ Ray Tune hyperparameter optimization completed!\n\n")

# RESULTS ===========================================================
print("=" * 50)
print("RESULTS")
print("=" * 50)

best_result = results_Random.get_best_result(metric=METRIC, mode="max")
print("üìù Best trial config:", best_result.config)
# print("üìù Best trial metrics:", best_result.metrics)

# Checkpoint
best_result.best_checkpoints

# EXPAND YOUR ANALYSIS:
# Get all results for deeper analysis
df_results = results_Random.get_dataframe()
sorted_df = df_results.sort_values(by="roc_auc", ascending=False)
print(f"\nüìù Total trials completed: {len(df_results)}")
print(f"üìù Best ROC AUC achieved: {df_results['roc_auc'].max():.4f}")
print(f"üìù Average ROC AUC: {df_results['roc_auc'].mean():.4f}")

# Mlflow Logging 
sorted_runs = mlflow.search_runs(
    experiment_names=[experiment_name],
    order_by=[f"metrics.{METRIC} DESC"]
)
mlflow.log_params(best_result.config)
# Filter out non-numeric values from the metrics dictionary
numeric_metrics = {k: v for k, v in best_result.metrics.items() if isinstance(v, (int, float))}
# Log only numeric metrics to MLflow
mlflow.log_metrics(numeric_metrics)

print("üìù Best trial logged to MLflow!")

# tensorboard --logdir /tmp/ray/session_2025-08-20_09-18-44_749895_74984/artifacts/2025-08-20_09-18-47/RAY_xgboost_els_roc_auc_random/driver_artifacts

# SAVE BEST MODEL ===========================================================

def save_best_model(best_result, X_train, y_train, X_val, y_val):
    """Recreate and save the best model with metadata"""
    
    # Convert NumPy arrays to pandas DataFrames/Series if necessary
    if isinstance(X_train, np.ndarray):
        X_train = pd.DataFrame(X_train)
    if isinstance(X_val, np.ndarray):
        X_val = pd.DataFrame(X_val)
    if isinstance(y_train, np.ndarray):
        y_train = pd.Series(y_train)
    if isinstance(y_val, np.ndarray):
        y_val = pd.Series(y_val)
    
    # Combine training and validation sets
    X_full_train = pd.concat([X_train, X_val])
    y_full_train = pd.concat([y_train, y_val])
    
    # Create models directory
    os.makedirs("models", exist_ok=True)
    
    # Recreate best model
    best_model = xgb.XGBClassifier(
        **best_result.config,
        tree_method="hist",
        random_state=42,
        eval_metric="logloss",
        verbosity=0
    )
    
    # Retrain on full training set (training + validation)
    best_model.fit(X_full_train, y_full_train)
    
    # Generate timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Save model
    model_path = f"models/ray/xgboost_ray_best_{timestamp}.pkl"
    joblib.dump(best_model, model_path)
    
    # Save metadata
    metadata = {
        "timestamp": timestamp,
        "model_type": "XGBoost_Ray_Tune",
        "best_config": best_result.config,
        "best_metrics": best_result.metrics,
        "training_samples": len(X_full_train),
        "validation_samples": len(X_val),  # For reference
        "search_algorithm": "Random Search"
    }
    
    metadata_path = f"models/ray/metadata_{timestamp}.json"
    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=2)
    
    print(f"‚úÖ Best model saved: {model_path}")
    print(f"‚úÖ Metadata saved: {metadata_path}")
    
    return best_model, model_path, metadata_path

best_model, model_path, metadata_path = save_best_model(
    best_result, 
    X_train, 
    y_train, 
    X_val, 
    y_val
)